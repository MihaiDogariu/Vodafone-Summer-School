{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/Vodafone-Summer-School/blob/main/DL_Crash_Course_Apps_1_%26_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clasificarea imaginilor\n",
        "Acest proiect implementeaza arhitectura AlexNet pentru clasificarea imaginilor reale și image retrieval. Baza de date aleasa pentru demonstratie este CIFAR10."
      ],
      "metadata": {
        "id": "cVj8IalH4YlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #TODO:\n",
        "1. Completați arhitectura rețelei cu modelul AlexNet\n",
        "1. Scrieți funcția de calcul a distanței între 2 tensori\n",
        "1. Rulați inferența(clasificarea) pe o imagine captată cu ajutorul camerei\n",
        "1. Găsiți cea mai asemănătoare imagine cu imaginea captată cu ajutorul camerei\n",
        "laptop-ului."
      ],
      "metadata": {
        "id": "ML4QO6PyB4Bw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nROe8lDRLzn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Alegem configuratia sistemului (cpu/gpu)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Setam media si deviatia standard pentru normalizarea bazei de date - acestea sunt calculate la nivel de canal si doar pe baza de date de antrenare!\n",
        "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Pre-procesarea datelor"
      ],
      "metadata": {
        "id": "Dj5xxj71llow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid_loader(data_dir,\n",
        "                           batch_size,\n",
        "                           augment,\n",
        "                           random_seed,\n",
        "                           normalize,\n",
        "                           valid_size=0.1,\n",
        "                           shuffle=True):\n",
        "\n",
        "    # Definim setul de transformari necesare bazei de date\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)), # baza de date CIFAR10 contine imagini de dimensiunea 32x32, iar AlexNet are intrari de dimensiune 227x227\n",
        "            transforms.ToTensor(),        # transformarea intrarilor in tensori\n",
        "            normalize,                    # aplicarea normalizarii\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4), # decuparea unor regiuni aleatoare de dimensiune 32x32 din imaginea originala la care s-a adaugat padding=4\n",
        "            transforms.RandomHorizontalFlip(0.4), # oglindirea imaginilor cu probabilitate de 40%\n",
        "            transforms.Resize((227,227)),         # redimensionarea imaginilor augmentate la dimensiunea de 227x227 pixeli\n",
        "            transforms.ToTensor(),                # transformarea intrarilor in tensori\n",
        "            normalize,                            # aplicarea normalizarii\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = valid_transform\n",
        "\n",
        "    # Fiind o baza de date foarte populara, CIFAR10 poate fi descarcata cu ajutorul modulului torchvision\n",
        "    train_dataset = datasets.CIFAR10(root=data_dir,\n",
        "                                     train=True,\n",
        "                                     download=True,\n",
        "                                     transform=train_transform,\n",
        "                                     )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(root=data_dir,\n",
        "                                     train=True,\n",
        "                                     download=True,\n",
        "                                     transform=valid_transform,\n",
        "                                     )\n",
        "\n",
        "    # Alegem numarul de esantioane pentru train/val\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    # Amestecam indecsii\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    # Separam indecsii de train in train+val\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # Cream dataloaders pentru train si val\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    normalize,\n",
        "                    shuffle=True):\n",
        "\n",
        "    # Transformari asemanatoare cu cele pentru train/val. Normalizarea se face cu aceleasi valori ca in cazul train!\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    # Descarcarea bazei de test\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    # Crearea dataloader pentru test\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "def get_dataset(data_dir):\n",
        "\n",
        "    # Transformari asemanatoare cu cele pentru train/val. Normalizarea se face cu aceleasi valori ca in cazul train!\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Descarcarea bazei de test\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Crearea efectiva a dataloaders\n",
        "train_loader, valid_loader = get_train_valid_loader(\n",
        "    data_dir = './data',\n",
        "    batch_size = 64,\n",
        "    augment = True,\n",
        "    random_seed = 1,\n",
        "    normalize = normalize\n",
        ")\n",
        "\n",
        "test_loader = get_test_loader(\n",
        "    data_dir = './data',\n",
        "    batch_size = 64,\n",
        "    normalize = normalize\n",
        ")\n",
        "\n",
        "dataset = get_dataset(\n",
        "     data_dir = './data'\n",
        ")\n",
        "\n",
        "infer_transform = transforms.Compose([\n",
        "                  transforms.Resize((227,227)),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "                  ])\n",
        "\n",
        "label_to_strings = {0:\"airplane\",\n",
        "                    1:\"automobile\",\n",
        "                    2:\"bird\",\n",
        "                    3:\"cat\",\n",
        "                    4:\"deer\",\n",
        "                    5:\"dog\",\n",
        "                    6:\"frog\",\n",
        "                    7:\"horse\",\n",
        "                    8:\"ship\",\n",
        "                    9:\"truck\"}"
      ],
      "metadata": {
        "id": "N4sJfy7RVUGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Definirea modelului"
      ],
      "metadata": {
        "id": "G90-dEwJ45Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resurse utile (documentatii):\n",
        "- strat convolutional: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "- strat complet conectat: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear\n",
        "- strat max pooling: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d\n",
        "- activare ReLU: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU\n",
        "- regularizare dropout: https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html?highlight=dropout#torch.nn.Dropout\n",
        "- mod secvential de compunere a straturilor: https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential"
      ],
      "metadata": {
        "id": "t-s_LREX7Qgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "\n",
        "\n",
        "        # TODO: de completat cu restul straturilor retelei\n",
        "\n",
        "\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def embedding(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IzVHcoKlXTko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Antrenarea rețelei"
      ],
      "metadata": {
        "id": "G8FsviED5BHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alegerea hiperparametrilor\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 64\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Trecerea modelului pe gpu\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "# Alegerea functiei de pierdere. Clasificare de imagini => cross-entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Alegerea optimizatorului\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)"
      ],
      "metadata": {
        "id": "nxoT-gGLXWKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antrenarea modelului\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Incarcam tensorii pe gpu/cpu\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward propagation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backprop si rularea unui pas de optimizare a ponderilor\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Rularea algoritmului pe baza de validare\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n"
      ],
      "metadata": {
        "id": "wyvxaODWXY_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Testarea rețelei"
      ],
      "metadata": {
        "id": "JjNYKyda5E_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rularea algoritmului pe baza de test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ],
      "metadata": {
        "id": "y9YOC0T0XbyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crearea bazei de vectori de trăsături pentru Image Retrieval"
      ],
      "metadata": {
        "id": "6PS6jtYNBdRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearea unei baze de date cu vectori de trasaturi\n",
        "feats = {}\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(len(dataset)):\n",
        "        image, label = dataset[i]\n",
        "        image = image[None, :].to(device)\n",
        "        feats[i] = model.embedding(image)"
      ],
      "metadata": {
        "id": "tsg10rLEBc33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funcții Ajutătoare"
      ],
      "metadata": {
        "id": "Gg0fmgSn-3V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_image(image):\n",
        "  with torch.no_grad():\n",
        "    image = infer_transform(image)\n",
        "    image = image[None, :].to(device)\n",
        "    model.eval()\n",
        "    output = model(image)\n",
        "    print (output)\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    predicted_class = torch.argmax(probabilities)\n",
        "    return probabilities, predicted_class\n",
        "\n",
        "def distance(tensor1, tensor2):\n",
        "  # TODO: de implementat distanta Euclidiana intre 2 tensori\n",
        "  pass\n",
        "\n",
        "def find_best_match(image):\n",
        "  with torch.no_grad():\n",
        "    image = infer_transform(image)\n",
        "    image = image[None, :].to(device)\n",
        "    model.eval()\n",
        "    query_feat = model.embedding(image)\n",
        "    print(query_feat)\n",
        "    min_dist = 999999\n",
        "    best_idx = -1\n",
        "    for (idx, feature) in feats.items():\n",
        "      torch_dist = distance(query_feat, feature)\n",
        "      if torch_dist < min_dist:\n",
        "        min_dist = torch_dist\n",
        "        best_idx = idx\n",
        "        print(best_idx, min_dist)\n",
        "    return best_idx\n",
        "\n",
        "def show_image_at_idx(idx):\n",
        "  image, label = dataset[idx]\n",
        "  image = np.transpose(image, (1, 2, 0))\n",
        "  plt.imshow(image)\n",
        "  plt.title(label_to_strings[label])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ZIy-MkqbloYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "w4DYlWhH82Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  # display(Image(filename))\n",
        "  im = Image.open(\"photo.jpg\")\n",
        "  plt.imshow(im)\n",
        "  plt.show()\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "JqaIdm1Y82Qo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}